{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2  (Due: 10/15/2018)\n",
    "\n",
    "COEN 281, Fall 2018  \n",
    "Professor Marwah\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this HW is to implement k-NN and cross-validation to find the best value of $k$ for a binary classification task. The task to diagnose breast cancer based on 30 numeric features. However, to keep things simple, we will only use two of those features. The output is binary: 0 benign, 1 malignant. In all there are 569 examples, which we will split into training and test sets. There are no missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "dat = sklearn.datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin (Diagnostic) Database\n",
      "=============================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "References\n",
      "----------\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# uncomment the following and run it to get a description of the data set\n",
    "print(dat.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dat is a dictionary with the data, let's see what keys it has\n",
    "dat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use two features: 'mean area' and 'mean concave points'\n",
    "ix1 = np.where(dat[\"feature_names\"] == \"mean area\")[0][0]\n",
    "ix2 = np.where(dat[\"feature_names\"] == \"mean concave points\")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 2) (569,)\n",
      "Number of points: 569\n",
      "range (min, max), X1: (143.50, 2501.00), X2: (0.00, 0.20)\n",
      "mean: 654.89, 0.05\n",
      "variance: 123843.55, 0.001506\n",
      "\n",
      "yes it is as both the features are in differnt scales and as they differ by a lot, the feature with the higher magnitude can dominate while calculating the euclidian distances.\n"
     ]
    }
   ],
   "source": [
    "X = dat[\"data\"][:,(ix1,ix2)]\n",
    "Y = dat[\"target\"]\n",
    "\n",
    "# verify shape of X and Y\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# stats of the two features\n",
    "from scipy import stats\n",
    "st = stats.describe(X)\n",
    "print(\"Number of points: %i\" % st.nobs)\n",
    "print(\"range (min, max), X1: (%.2f, %.2f), X2: (%.2f, %.2f)\" % (st.minmax[0][0], st.minmax[1][0], st.minmax[0][1], st.minmax[1][1]))\n",
    "print(\"mean: %.2f, %.2f\" % (st.mean[0], st.mean[1]))\n",
    "print(\"variance: %.2f, %f\" % (st.variance[0], st.variance[1]))\n",
    "\n",
    "# Given the stats, is it a good idea to normalize the features? \n",
    "#yes it is as both the features are in differnt scales and as they differ by a lot, the feature with the higher magnitude can dominate while calculating the euclidian distances.\n",
    "\n",
    "#\n",
    "# add code to normalize features\n",
    "#\n",
    "print()\n",
    "print(\"yes it is as both the features are in differnt scales and as they differ by a lot, the feature with the higher magnitude can dominate while calculating the euclidian distances.\")\n",
    "for i in range(X.shape[1]):\n",
    "    X[:,i]=(X[:,i]-X[:,i].min())/(X[:,i].max()-X[:,i].min())\n",
    "\n",
    "#print((np.around(normalized_df,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 2) (398,) (171, 2) (171,)\n"
     ]
    }
   ],
   "source": [
    "# split into training set / test set\n",
    "#\n",
    "# usually you would do the split randomly; here for deterministic results, we assume the data \n",
    "# points are already shuffled and take the first 70% as training and the rest as test\n",
    "#\n",
    "nTot = X.shape[0]\n",
    "nTr = int(nTot*0.7)\n",
    "nTs = nTot - nTr\n",
    "\n",
    "Xtr = X[0:nTr,]\n",
    "Ytr = Y[0:nTr]\n",
    "\n",
    "Xts = X[nTr:nTot,]\n",
    "Yts = Y[nTr:nTot,]\n",
    "\n",
    "# verify shapes\n",
    "print(Xtr.shape, Ytr.shape, Xts.shape, Yts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the following functions for k-NN\n",
    "#\n",
    "\n",
    "#\n",
    "# knn_predict(Xtr, Ytr, Xts, k)\n",
    "#\n",
    "# input: Xtr - training examples input features, size nXd\n",
    "#        Ytr - label (can assume to be binary 0/1), size nX1\n",
    "#        Xts - test examples input features, for which labels (Yts) \n",
    "#              need to be predicted, size mXd\n",
    "#        k   - k for the k-NN algo \n",
    "#\n",
    "# output: Yts - 0/1 labes for Xts, size mX1\n",
    "#\n",
    "#  This function predicts the binary labels for Xts, given the training\n",
    "#  data Xtr, Ytr and k, using the k-NN algorithm\n",
    "#\n",
    "import math\n",
    "import random\n",
    "def knn_predict(Xtr, Ytr, Xts, k):\n",
    "    # compute in two steps\n",
    "    \n",
    "    # step 1: compute dist matrix between Xts and Xtr\n",
    "    \n",
    "    dist = compute_dist_mat(Xtr, Xts)\n",
    "    dist = np.asarray(dist)\n",
    "    index_sort = np.argsort(dist)\n",
    "    \n",
    "    # step 2: use the dist matrix and use k-nn to find labels for Xts \n",
    "    # hint: function numpy.argsort may be useful\n",
    "    # in case of a tie, pick a class randomly\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    neighbours = []\n",
    "    for i in range(0, len(dist)):\n",
    "        neighbours.append([])\n",
    "        neighbours[i] = index_sort[i][0:k].tolist()\n",
    "        for j in range(0, len(neighbours[i])):\n",
    "            neighbours[i][j] = Ytr[neighbours[i][j]]\n",
    "    prediction = []\n",
    "    for i in range(0,len(neighbours)):\n",
    "        prediction.append([])\n",
    "        count_one = 0\n",
    "        count_zero = 0\n",
    "        for j in range(0, k):\n",
    "            if neighbours[i][j] == 1:\n",
    "                count_one = count_one + 1\n",
    "            if neighbours[i][j] == 0:\n",
    "                count_zero = count_zero + 1\n",
    "        if count_one > count_zero:\n",
    "            res = 1\n",
    "        elif count_zero > count_one:\n",
    "            res = 0\n",
    "        else:\n",
    "            res = random.randint(0,1)\n",
    "        prediction[i].append(res)\n",
    "    pred = np.asarray(prediction)\n",
    "    return pred\n",
    "    pass\n",
    "\n",
    "#  compute_dist_mat(Xts, Xtr)\n",
    "#\n",
    "#  input: Xts - test examples, size mXd\n",
    "#         Xtr - training examples, size nXd\n",
    "#  output: L2 distance matrix mXn\n",
    "#\n",
    "#   if Xts is mXd, and Xtr is nXd, this function returns a matrix of size mXn with the L2 distances; the (i,j) \n",
    "#     entry of the matrix is the L2 distance between ith test and jth training example \n",
    "\n",
    "def compute_dist_mat(Xtr, Xts):    \n",
    "    # use two for loops to compute the matrix\n",
    "    # YOUR CODE HERE\n",
    "    dist_matrix = []\n",
    "    for i in range(0, len(Xts)):\n",
    "        dist_matrix.append([])\n",
    "        for j in range(0, len(Xtr)):\n",
    "            x = Xts[i][0] -  Xtr[j][0];\n",
    "            y = Xts[i][1] -  Xtr[j][1];\n",
    "            dist = math.sqrt(x**2 + y**2)\n",
    "            dist_matrix[i].append(dist)\n",
    "    return dist_matrix\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 (30 points): Fill-in code for normalizing features, and the above two functions to implement k-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2 (20 points): Run your k-NN implementation on the test data set. Use k=5. Compute accuracy, recall and precision of the test data set (do not use python library functions to compute these). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9122807017543859\n",
      "precession = 0.9915966386554622\n",
      "recall = 0.8939393939393939\n"
     ]
    }
   ],
   "source": [
    "# problem 2 solution\n",
    "predected_label = knn_predict(Xtr, Ytr, Xts, 5)\n",
    "predected_label = predected_label.flatten()\n",
    "Yts = np.asarray(Yts)\n",
    "diff_accuracy = np.subtract(Yts,predected_label)\n",
    "sum_accuracy = np.add(Yts,predected_label)\n",
    "unique_sum, counts_sum = np.unique(sum_accuracy, return_counts=True)\n",
    "unique_diff, counts_diff = np.unique(diff_accuracy, return_counts=True)\n",
    "true_values = dict(zip(unique_diff, counts_diff))[0]\n",
    "total = true_values + dict(zip(unique_diff, counts_diff))[-1]+ dict(zip(unique_diff, counts_diff))[1]\n",
    "accuracy = true_values/total\n",
    "precession = dict(zip(unique_sum, counts_sum))[2]/(dict(zip(unique_sum, counts_sum))[2] + dict(zip(unique_diff, counts_diff))[-1])\n",
    "recall = dict(zip(unique_sum, counts_sum))[2]/(dict(zip(unique_sum, counts_sum))[2] + dict(zip(unique_diff, counts_diff))[1])\n",
    "print(\"accuracy = {}\".format(accuracy))\n",
    "print(\"precession = {}\".format(precession))\n",
    "print(\"recall = {}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "Priblem 3 (30 points): Now we will implement 5-fold cross-validation to find the best value of $k$. And then using that value of $k$, re-run k-NN on the test data set. (This is adapted from a past Stanford cs231n assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1, accuracy = 0.787500\n",
      "k = 1, accuracy = 0.787500\n",
      "k = 1, accuracy = 0.875000\n",
      "k = 1, accuracy = 0.873418\n",
      "k = 1, accuracy = 0.898734\n",
      "k = 3, accuracy = 0.787500\n",
      "k = 3, accuracy = 0.812500\n",
      "k = 3, accuracy = 0.887500\n",
      "k = 3, accuracy = 0.911392\n",
      "k = 3, accuracy = 0.886076\n",
      "k = 5, accuracy = 0.825000\n",
      "k = 5, accuracy = 0.837500\n",
      "k = 5, accuracy = 0.900000\n",
      "k = 5, accuracy = 0.936709\n",
      "k = 5, accuracy = 0.911392\n",
      "k = 7, accuracy = 0.837500\n",
      "k = 7, accuracy = 0.837500\n",
      "k = 7, accuracy = 0.875000\n",
      "k = 7, accuracy = 0.949367\n",
      "k = 7, accuracy = 0.924051\n",
      "k = 9, accuracy = 0.850000\n",
      "k = 9, accuracy = 0.837500\n",
      "k = 9, accuracy = 0.900000\n",
      "k = 9, accuracy = 0.924051\n",
      "k = 9, accuracy = 0.936709\n",
      "k = 11, accuracy = 0.850000\n",
      "k = 11, accuracy = 0.825000\n",
      "k = 11, accuracy = 0.912500\n",
      "k = 11, accuracy = 0.924051\n",
      "k = 11, accuracy = 0.936709\n",
      "k = 13, accuracy = 0.887500\n",
      "k = 13, accuracy = 0.825000\n",
      "k = 13, accuracy = 0.912500\n",
      "k = 13, accuracy = 0.924051\n",
      "k = 13, accuracy = 0.911392\n",
      "k = 15, accuracy = 0.875000\n",
      "k = 15, accuracy = 0.837500\n",
      "k = 15, accuracy = 0.925000\n",
      "k = 15, accuracy = 0.924051\n",
      "k = 15, accuracy = 0.911392\n",
      "k = 20, accuracy = 0.850000\n",
      "k = 20, accuracy = 0.850000\n",
      "k = 20, accuracy = 0.912500\n",
      "k = 20, accuracy = 0.911392\n",
      "k = 20, accuracy = 0.936709\n",
      "k = 30, accuracy = 0.850000\n",
      "k = 30, accuracy = 0.837500\n",
      "k = 30, accuracy = 0.937500\n",
      "k = 30, accuracy = 0.936709\n",
      "k = 30, accuracy = 0.936709\n",
      "k = 40, accuracy = 0.825000\n",
      "k = 40, accuracy = 0.837500\n",
      "k = 40, accuracy = 0.937500\n",
      "k = 40, accuracy = 0.924051\n",
      "k = 40, accuracy = 0.949367\n",
      "k = 50, accuracy = 0.837500\n",
      "k = 50, accuracy = 0.850000\n",
      "k = 50, accuracy = 0.937500\n",
      "k = 50, accuracy = 0.924051\n",
      "k = 50, accuracy = 0.962025\n",
      "k = 75, accuracy = 0.825000\n",
      "k = 75, accuracy = 0.850000\n",
      "k = 75, accuracy = 0.937500\n",
      "k = 75, accuracy = 0.924051\n",
      "k = 75, accuracy = 0.962025\n",
      "k = 100, accuracy = 0.800000\n",
      "k = 100, accuracy = 0.862500\n",
      "k = 100, accuracy = 0.925000\n",
      "k = 100, accuracy = 0.924051\n",
      "k = 100, accuracy = 0.962025\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "k_choices = [1, 3, 5, 7, 9, 11, 13, 15, 20, 30, 40, 50, 75, 100]\n",
    "\n",
    "X_train_folds = []\n",
    "y_train_folds = []\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Split up the training data into folds. After splitting, X_train_folds and    #\n",
    "# y_train_folds should each be lists of length num_folds, where                #\n",
    "# y_train_folds[i] is the label vector for the points in X_train_folds[i].     #\n",
    "# Hint: Look up the numpy array_split function.                                #\n",
    "################################################################################\n",
    "X_train_folds = np.array(np.array_split(Xtr, num_folds))\n",
    "y_train_folds = np.array(np.array_split(Ytr, num_folds))\n",
    "pass\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "# A dictionary holding the accuracies for different values of k that we find\n",
    "# when running cross-validation. After running cross-validation,\n",
    "# k_to_accuracies[k] should be a list of length num_folds giving the different\n",
    "# accuracy values that we found when using that value of k.\n",
    "k_to_accuracies = {}\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Perform k-fold cross validation to find the best value of k. For each        #\n",
    "# possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #\n",
    "# where in each case you use all but one of the folds as training data and the #\n",
    "# last fold as a validation set. Store the accuracies for all fold and all     #\n",
    "# values of k in the k_to_accuracies dictionary.                               #\n",
    "################################################################################\n",
    "for k in k_choices:\n",
    "    for n in range(num_folds):\n",
    "        test_num_fold_set = [x for x in range(num_folds) if x != n]\n",
    "        x_training_dat = np.concatenate(X_train_folds[test_num_fold_set])\n",
    "        y_training_dat = np.concatenate(y_train_folds[test_num_fold_set])\n",
    "        predected_label = knn_predict(x_training_dat, y_training_dat, X_train_folds[n], k)\n",
    "        predected_label = predected_label.flatten()\n",
    "        sum_accuracy = np.add(y_train_folds[n],predected_label)\n",
    "        unique, counts = np.unique(sum_accuracy, return_counts=True)\n",
    "        true_values = dict(zip(unique, counts))[0] + dict(zip(unique, counts))[2]\n",
    "        total = true_values + dict(zip(unique, counts))[1]\n",
    "        accuracy = true_values/total\n",
    "        k_to_accuracies.setdefault(k, []).append(accuracy)\n",
    "pass\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "# Print out the computed accuracies\n",
    "for k in sorted(k_to_accuracies):\n",
    "    for accuracy in k_to_accuracies[k]:\n",
    "        print('k = %d, accuracy = %f' % (k, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the raw observations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "for k in k_choices:\n",
    "    accuracies = k_to_accuracies[k]\n",
    "    plt.scatter([k] * len(accuracies), accuracies)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4 (20 points): Based on the cross-validation results above, choose the best value for $k$. Repeat problem 2 with this $k$ (using the entire training data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value is 50\n",
      "accuracy = 0.9239766081871345\n",
      "precession = 0.976\n",
      "recall = 0.9242424242424242\n"
     ]
    }
   ],
   "source": [
    "mean = []\n",
    "for k in sorted(k_to_accuracies):\n",
    "    mean.append(np.mean(k_to_accuracies.get(k)))\n",
    "mean = np.asarray(mean)\n",
    "mean = np.argsort(mean)\n",
    "best_k = k_choices[mean[len(mean) - 1]]\n",
    "print(\"Best K value is {}\".format(best_k))\n",
    "predected_label = knn_predict(Xtr, Ytr, Xts, best_k)\n",
    "predected_label = predected_label.flatten()\n",
    "Yts = np.asarray(Yts)\n",
    "diff_accuracy = np.subtract(Yts,predected_label)\n",
    "sum_accuracy = np.add(Yts,predected_label)\n",
    "unique_sum, counts_sum = np.unique(sum_accuracy, return_counts=True)\n",
    "unique_diff, counts_diff = np.unique(diff_accuracy, return_counts=True)\n",
    "true_values = dict(zip(unique_diff, counts_diff))[0]\n",
    "total = true_values + dict(zip(unique_diff, counts_diff))[-1]+ dict(zip(unique_diff, counts_diff))[1]\n",
    "accuracy = true_values/total\n",
    "precession = dict(zip(unique_sum, counts_sum))[2]/(dict(zip(unique_sum, counts_sum))[2] + dict(zip(unique_diff, counts_diff))[-1])\n",
    "recall = dict(zip(unique_sum, counts_sum))[2]/(dict(zip(unique_sum, counts_sum))[2] + dict(zip(unique_diff, counts_diff))[1])\n",
    "print(\"accuracy = {}\".format(accuracy))\n",
    "print(\"precession = {}\".format(precession))\n",
    "print(\"recall = {}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: these extra credit problems are optional and only increase your score marginally. \n",
    "\n",
    "Extra Credit Problem 1 (5 points): Plot decision boundaries for the best $k$, similar to how it is done here:\n",
    "http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html\n",
    "\n",
    "Extra Credit Problem 2 (5 points): In problem 1 above, re-write the compute_dist_mat() function with no loops. That may seem non-intuitive, but it is possible to compute the L2 distances using matrix operations (matrix multiplication, addition, etc.) without explicitly doing the double for loop. The advantage of using matrix operations is that they are highly optimized and enable \"vectorization\", and for such computations can give 10-100x speed improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
